# üìò Guide d'Utilisation des Scripts - NexSlice

## üéØ Vue d'Ensemble

Ce guide vous explique comment utiliser les 4 scripts de test fournis pour valider votre infrastructure 5G et collecter des m√©triques de performance avec **monitoring en temps r√©el via Prometheus et Grafana**.

---

## üì¶ Scripts Disponibles

| Script | R√¥le | Dur√©e | Privil√®ges |
|--------|------|-------|------------|
| `test-connectivity.sh` | Test connectivit√© 5G de base | ~30s | Utilisateur |
| `test-video-streaming.sh` | Test streaming vid√©o complet | ~2-5 min | **sudo** |
| `measure-performance.sh` | Mesures r√©seau d√©taill√©es | ~2 min | Utilisateur* |
| `run-all-tests.sh` | Orchestration compl√®te | ~5-10 min | **sudo** |

*\* Certaines fonctionnalit√©s n√©cessitent sudo*

---

## üöÄ Utilisation

### Pr√©requis

Avant de lancer les scripts, assurez-vous que:

1. **L'infrastructure NexSlice est d√©ploy√©e**:
```bash
# V√©rifier que tous les pods du Core 5G sont Running
kubectl get pods -n nexslice

# Vous devriez voir:
# - AMF, SMF, UPF, NRF, AUSF, UDM, etc. en "Running"
# - gNB UERANSIM en "Running"
# - UE UERANSIM en "Running"
```

2. **L'interface tunnel est cr√©√©e**:
```bash
# V√©rifier que uesimtun0 existe
ip link show uesimtun0

# Devrait afficher quelque chose comme:
# 5: uesimtun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UNKNOWN mode DEFAULT group default qlen 500
```

3. **Les outils n√©cessaires sont install√©s**:
```bash
# Installation des d√©pendances
sudo apt update
sudo apt install -y iputils-ping curl tcpdump iperf3 jq bc
```

4. **Prometheus et Grafana sont d√©ploy√©s** (voir section [Monitoring](#-monitoring-avec-prometheus-et-grafana))

---

## üìù Script 1: test-connectivity.sh

### Description
V√©rifie la connectivit√© 5G de base vers l'UPF.

### Utilisation
```bash
cd scripts/
./test-connectivity.sh
```

### Ce qu'il fait
1. ‚úÖ V√©rifie l'existence de l'interface `uesimtun0`
2. ‚úÖ V√©rifie l'IP du UE (12.1.1.2)
3. ‚úÖ V√©rifie le routage vers l'UPF
4. ‚úÖ Envoie 10 pings vers l'UPF (12.1.1.1)
5. ‚úÖ Teste l'acc√®s Internet (optionnel)

### R√©sultat Attendu
```
================================================
  Test de Connectivit√© 5G - NexSlice
================================================

[1/5] V√©rification interface uesimtun0...
‚úì Interface uesimtun0 existe
D√©tails interface:
    inet 12.1.1.2/32 scope global uesimtun0

[2/5] V√©rification IP du UE...
‚úì IP UE correcte: 12.1.1.2

[3/5] V√©rification routing via UPF...
‚úì Route configur√©e via uesimtun0

[4/5] Test ping vers UPF Gateway (12.1.1.1)...
Envoi de 10 paquets ICMP...
‚úì Connectivit√© 5G vers UPF
Statistiques:
  - Latence moyenne: 2.456 ms
  - Perte de paquets: 0%

[5/5] Test r√©solution DNS...
‚úì Acc√®s Internet via tunnel 5G

================================================
‚úì Tests de connectivit√© termin√©s avec succ√®s
================================================
```

### D√©pannage

**Probl√®me**: Interface uesimtun0 n'existe pas
```bash
# V√©rifier les logs du UE UERANSIM
kubectl logs -n nexslice <ue-pod-name>

# Rechercher: "Connection setup for PDU session[1] is successful"
```

**Probl√®me**: Ping vers UPF √©choue
```bash
# V√©rifier que l'UPF est actif
kubectl get pods -n nexslice | grep upf

# V√©rifier les logs UPF
kubectl logs -n nexslice <upf-pod-name>
```

---

## üé• Script 2: test-video-streaming.sh

### Description
Teste le streaming vid√©o via le tunnel 5G avec m√©triques d√©taill√©es et export vers Prometheus.

### Utilisation
```bash
cd scripts/
sudo ./test-video-streaming.sh
```

‚ö†Ô∏è **N√©cessite sudo** pour la capture tcpdump

### Ce qu'il fait
1. ‚úÖ V√©rifie l'interface 5G
2. ‚úÖ T√©l√©charge une vid√©o (Big Buck Bunny, ~158 MB) via le tunnel
3. ‚úÖ Mesure le d√©bit, temps de t√©l√©chargement
4. ‚úÖ **Exporte les m√©triques vers Prometheus**
5. ‚úÖ V√©rifie le routage via UPF

### R√©sultat Attendu
```
================================================
  Test Streaming Vid√©o via Slice 5G (SST=1)
================================================

[1/4] V√©rification interface 5G...
‚úì Interface uesimtun0 active
  IP du UE: 12.1.1.2

[2/4] T√©l√©chargement vid√©o via tunnel 5G...
  URL: http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4
  Interface: uesimtun0

=== M√©triques de T√©l√©chargement ===
Temps total: 45.234s
Temps connexion: 0.123s
Temps d√©marrage transfert: 0.456s
Vitesse download: 3456789 bytes/s
Taille t√©l√©charg√©e: 158000000 bytes
Code HTTP: 200
IP source: 12.1.1.2
================================

‚úì T√©l√©chargement r√©ussi
Temps √©coul√©: 45s
  Taille fichier: 151M
  D√©bit moyen: 27.96 Mbps

[3/4] Export des m√©triques vers Prometheus...
‚úì M√©triques export√©es
  Endpoint: http://localhost:9091/metrics/job/nexslice_test

[4/4] V√©rification du routage via UPF...
  IP source (UE): 12.1.1.2
  IP destination: 142.250.185.48
  Gateway UPF: 12.1.1.1
‚úì Trafic rout√© via le tunnel 5G

================================================
‚úì Test de streaming termin√© avec succ√®s
‚úì Consultez Grafana: http://localhost:3000
================================================
```

### Fichiers G√©n√©r√©s
```
results/
‚îú‚îÄ‚îÄ video_20251129_123456.mp4           # Vid√©o t√©l√©charg√©e
‚îî‚îÄ‚îÄ curl_metrics_20251129_123456.txt    # M√©triques curl
```

---

## üìä Script 3: measure-performance.sh

### Description
Mesure d√©taill√©e de performance r√©seau (latence, jitter, d√©bit) avec export Prometheus.

### Utilisation
```bash
cd scripts/
./measure-performance.sh
```

### Ce qu'il fait
1. ‚úÖ **Test 1**: Latence et jitter (100 pings)
2. ‚úÖ **Test 2**: D√©bit avec iperf3 (optionnel si serveur disponible)
3. ‚úÖ **Test 3**: Statistiques interface r√©seau
4. ‚úÖ **Exporte toutes les m√©triques vers Prometheus**
5. ‚úÖ G√©n√®re un rapport Markdown

### R√©sultat Attendu
```
================================================
  Mesures de Performance - Slice eMBB (SST=1)
================================================

[Pr√©requis] V√©rification des outils n√©cessaires...
‚úì Interface uesimtun0 active (IP: 12.1.1.2)

================================================
[Test 1/3] Mesure Latence et Jitter
================================================
Destination: 12.1.1.1
Nombre de pings: 100

Envoi des paquets ICMP...
R√©sultats Latence:
  - RTT Min:     1.234 ms
  - RTT Moyen:   2.456 ms
  - RTT Max:     5.678 ms
  - Jitter (mdev): 0.789 ms
  - Perte:       0%
‚úì Fichier sauvegard√©: results/performance/ping_20251129_123456.json
‚úì M√©triques export√©es vers Prometheus

================================================
[Test 2/3] Mesure D√©bit (iperf3)
================================================
Entrez l'IP du serveur iperf3 (ou appuyez sur Entr√©e pour sauter):
[attend 10 secondes]
‚ö† Test iperf3 ignor√© (pas de serveur configur√©)

Pour activer ce test:
  1. Sur une machine avec acc√®s r√©seau, lancez:
     iperf3 -s
  2. Relancez ce script et entrez l'IP du serveur

================================================
[Test 3/3] Statistiques Interface 5G
================================================
Test de charge (10s de trafic)...
Statistiques RX/TX:
    RX: bytes  packets  errors  dropped  overrun  mcast
    1234567    8901     0       0        0        0
    TX: bytes  packets  errors  dropped  carrier  collsns
    9876543    7890     0       0        0        0
‚úì Fichier sauvegard√©: results/performance/interface_stats_20251129_123456.txt
‚úì M√©triques export√©es vers Prometheus

================================================
  G√©n√©ration du Rapport
================================================
‚úì Rapport g√©n√©r√©: results/performance/rapport_performance_20251129_123456.md
‚úì Dashboard Grafana mis √† jour: http://localhost:3000/d/nexslice
```

### Fichiers G√©n√©r√©s
```
results/performance/
‚îú‚îÄ‚îÄ ping_20251129_123456.json          # M√©triques latence (JSON)
‚îú‚îÄ‚îÄ ping_20251129_123456.txt           # Sortie brute ping
‚îú‚îÄ‚îÄ interface_stats_20251129_123456.txt # Stats interface
‚îî‚îÄ‚îÄ rapport_performance_20251129_123456.md # Rapport complet
```

---

## üìà Monitoring avec Prometheus et Grafana

### Installation et Configuration

#### 1. D√©ployer Prometheus
```bash
# Cr√©er le namespace monitoring
kubectl create namespace monitoring

# Cr√©er la configuration Prometheus
cat > monitoring/prometheus-config.yaml << 'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'nexslice'
        replica: '1'

    scrape_configs:
      # M√©triques des pods Kubernetes
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - nexslice
                - monitoring
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__

      # M√©triques des scripts de test (Pushgateway)
      - job_name: 'pushgateway'
        honor_labels: true
        static_configs:
          - targets: ['pushgateway:9091']

      # Node exporter pour m√©triques syst√®me
      - job_name: 'node-exporter'
        static_configs:
          - targets: ['node-exporter:9100']
            labels:
              node: 'nexslice-node'

      # M√©triques r√©seau personnalis√©es
      - job_name: 'nexslice-ue'
        static_configs:
          - targets: ['ue-exporter:9102']
            labels:
              slice_type: 'embb'
              sst: '1'
EOF

kubectl apply -f monitoring/prometheus-config.yaml

# D√©ployer Prometheus
cat > monitoring/prometheus-deployment.yaml << 'EOF'
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  type: NodePort
  ports:
    - port: 9090
      targetPort: 9090
      nodePort: 30090
  selector:
    app: prometheus
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--web.console.libraries=/usr/share/prometheus/console_libraries'
          - '--web.console.templates=/usr/share/prometheus/consoles'
          - '--storage.tsdb.retention.time=30d'
          - '--web.enable-lifecycle'
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        emptyDir: {}
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
EOF

kubectl apply -f monitoring/prometheus-deployment.yaml
```

#### 2. D√©ployer Pushgateway (pour les scripts)
```bash
cat > monitoring/pushgateway-deployment.yaml << 'EOF'
apiVersion: v1
kind: Service
metadata:
  name: pushgateway
  namespace: monitoring
spec:
  type: NodePort
  ports:
    - port: 9091
      targetPort: 9091
      nodePort: 30091
  selector:
    app: pushgateway
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pushgateway
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pushgateway
  template:
    metadata:
      labels:
        app: pushgateway
    spec:
      containers:
      - name: pushgateway
        image: prom/pushgateway:latest
        ports:
        - containerPort: 9091
EOF

kubectl apply -f monitoring/pushgateway-deployment.yaml
```

#### 3. D√©ployer Grafana
```bash
cat > monitoring/grafana-deployment.yaml << 'EOF'
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  type: NodePort
  ports:
    - port: 3000
      targetPort: 3000
      nodePort: 30300
  selector:
    app: grafana
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: monitoring
data:
  prometheus.yaml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
      editable: true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: "admin"
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-datasources
          mountPath: /etc/grafana/provisioning/datasources
      volumes:
      - name: grafana-storage
        emptyDir: {}
      - name: grafana-datasources
        configMap:
          name: grafana-datasources
EOF

kubectl apply -f monitoring/grafana-deployment.yaml
```

#### 4. V√©rifier le d√©ploiement
```bash
# V√©rifier que tous les pods sont Running
kubectl get pods -n monitoring

# Devrait afficher:
# NAME                           READY   STATUS    RESTARTS   AGE
# prometheus-xxxxx              1/1     Running   0          2m
# pushgateway-xxxxx             1/1     Running   0          2m
# grafana-xxxxx                 1/1     Running   0          2m

# Acc√©der aux interfaces
echo "Prometheus: http://localhost:30090"
echo "Pushgateway: http://localhost:30091"
echo "Grafana: http://localhost:30300"
```

---

### Modifier les Scripts pour Exporter vers Prometheus

#### Script d'export des m√©triques

Cr√©ez un fichier `scripts/export-to-prometheus.sh`:
```bash
#!/bin/bash

PUSHGATEWAY_URL="http://localhost:30091"
JOB_NAME="nexslice_test"

# Fonction pour exporter des m√©triques
export_metric() {
    local metric_name=$1
    local metric_value=$2
    local labels=$3
    
    cat <<EOF | curl --data-binary @- ${PUSHGATEWAY_URL}/metrics/job/${JOB_NAME}${labels}
# TYPE ${metric_name} gauge
${metric_name} ${metric_value}
EOF
}

# Exemple: exporter la latence
export_metric "nexslice_latency_ms" "2.456" "/ue_ip/12.1.1.2/slice_type/embb"

# Exemple: exporter le d√©bit
export_metric "nexslice_throughput_mbps" "27.96" "/ue_ip/12.1.1.2/slice_type/embb"

# Exemple: exporter la perte de paquets
export_metric "nexslice_packet_loss_percent" "0" "/ue_ip/12.1.1.2/slice_type/embb"
```

#### Modifier `measure-performance.sh`

Ajoutez √† la fin du script:
```bash
# Export vers Prometheus
echo ""
echo "================================================"
echo "[Export] Envoi des m√©triques vers Prometheus"
echo "================================================"

PUSHGATEWAY_URL="http://localhost:30091"
JOB_NAME="nexslice_performance"
UE_IP=$(ip addr show uesimtun0 | grep "inet " | awk '{print $2}' | cut -d'/' -f1)

# Exporter latence
cat <<EOF | curl --silent --data-binary @- ${PUSHGATEWAY_URL}/metrics/job/${JOB_NAME}/ue_ip/${UE_IP}/slice_type/embb
# TYPE nexslice_rtt_min_ms gauge
nexslice_rtt_min_ms ${RTT_MIN}
# TYPE nexslice_rtt_avg_ms gauge
nexslice_rtt_avg_ms ${RTT_AVG}
# TYPE nexslice_rtt_max_ms gauge
nexslice_rtt_max_ms ${RTT_MAX}
# TYPE nexslice_jitter_ms gauge
nexslice_jitter_ms ${JITTER}
# TYPE nexslice_packet_loss_percent gauge
nexslice_packet_loss_percent ${PACKET_LOSS}
EOF

echo "‚úì M√©triques export√©es vers Prometheus"
echo "  Endpoint: ${PUSHGATEWAY_URL}/metrics"
```

---

### Dashboards Grafana Recommand√©s

#### Dashboard 1: Vue d'Ensemble NexSlice

Cr√©ez un fichier `monitoring/grafana-dashboard-overview.json`:
```json
{
  "dashboard": {
    "title": "NexSlice - Vue d'Ensemble",
    "panels": [
      {
        "title": "Latence Moyenne (ms)",
        "targets": [
          {
            "expr": "nexslice_rtt_avg_ms{slice_type=\"embb\"}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "D√©bit (Mbps)",
        "targets": [
          {
            "expr": "nexslice_throughput_mbps{slice_type=\"embb\"}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Perte de Paquets (%)",
        "targets": [
          {
            "expr": "nexslice_packet_loss_percent{slice_type=\"embb\"}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Jitter (ms)",
        "targets": [
          {
            "expr": "nexslice_jitter_ms{slice_type=\"embb\"}"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

#### Dashboard 2: Comparaison Multi-Slices

Pour comparer SST 1, 2, 3:
```json
{
  "dashboard": {
    "title": "NexSlice - Comparaison Slices",
    "panels": [
      {
        "title": "Latence par Slice",
        "targets": [
          {
            "expr": "nexslice_rtt_avg_ms",
            "legendFormat": "SST {{sst}} - {{slice_type}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "D√©bit par Slice",
        "targets": [
          {
            "expr": "nexslice_throughput_mbps",
            "legendFormat": "SST {{sst}} - {{slice_type}}"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

---

### Importer les Dashboards dans Grafana
```bash
# 1. Acc√©der √† Grafana
open http://localhost:30300
# Login: admin / admin

# 2. Ajouter la source de donn√©es Prometheus
# - Aller dans Configuration > Data Sources
# - Add data source > Prometheus
# - URL: http://prometheus:9090
# - Save & Test

# 3. Importer les dashboards
# - Aller dans Create > Import
# - Uploader le fichier JSON ou coller le contenu
# - S√©lectionner la source de donn√©es Prometheus
# - Import
```

---

### Requ√™tes Prometheus Utiles
```promql
# Latence moyenne sur les 5 derni√®res minutes
avg_over_time(nexslice_rtt_avg_ms{ue_ip="12.1.1.2"}[5m])

# D√©bit maximum
max_over_time(nexslice_throughput_mbps{ue_ip="12.1.1.2"}[5m])

# Perte de paquets totale
sum(nexslice_packet_loss_percent{slice_type="embb"})

# Comparaison latence entre slices
nexslice_rtt_avg_ms{sst=~"1|2|3"}

# Alertes si latence > 50ms
nexslice_rtt_avg_ms > 50

# Alertes si perte de paquets > 1%
nexslice_packet_loss_percent > 1
```

---

### Avantages par rapport √† Wireshark/tcpdump

| Crit√®re | Wireshark/tcpdump | Prometheus + Grafana |
|---------|-------------------|----------------------|
| **Temps r√©el** | ‚ùå Post-mortem | ‚úÖ Live monitoring |
| **Historique** | ‚ùå Par capture | ‚úÖ 30 jours (configurable) |
| **Alertes** | ‚ùå Non | ‚úÖ Oui (r√®gles Prometheus) |
| **Multi-UE** | ‚ö†Ô∏è Difficile | ‚úÖ Facile (labels) |
| **Dashboards** | ‚ùå Non | ‚úÖ Oui (personnalisables) |
| **Comparaison slices** | ‚ö†Ô∏è Manuel | ‚úÖ Automatique |
| **Analyse r√©seau** | ‚úÖ D√©taill√©e | ‚ö†Ô∏è M√©triques agr√©g√©es |

**Recommandation**: Utilisez Prometheus+Grafana pour le monitoring continu et les tests de performance. Gardez tcpdump pour le debug approfondi si n√©cessaire.

---

## üìä Exploiter les R√©sultats avec Grafana

### 1. Cr√©er un Rapport Automatique
```bash
# Script pour g√©n√©rer un rapport depuis Prometheus
cat > scripts/generate-report-from-prometheus.sh << 'EOF'
#!/bin/bash

PROMETHEUS_URL="http://localhost:30090"
UE_IP="12.1.1.2"

# R√©cup√©rer la latence moyenne
RTT_AVG=$(curl -s "${PROMETHEUS_URL}/api/v1/query?query=nexslice_rtt_avg_ms{ue_ip=\"${UE_IP}\"}" | jq -r '.data.result[0].value[1]')

# R√©cup√©rer le d√©bit
THROUGHPUT=$(curl -s "${PROMETHEUS_URL}/api/v1/query?query=nexslice_throughput_mbps{ue_ip=\"${UE_IP}\"}" | jq -r '.data.result[0].value[1]')

# R√©cup√©rer la perte de paquets
PACKET_LOSS=$(curl -s "${PROMETHEUS_URL}/api/v1/query?query=nexslice_packet_loss_percent{ue_ip=\"${UE_IP}\"}" | jq -r '.data.result[0].value[1]')

# G√©n√©rer le tableau
echo "| M√©trique | Valeur |"
echo "|----------|--------|"
echo "| Latence moyenne | ${RTT_AVG} ms |"
echo "| D√©bit moyen | ${THROUGHPUT} Mbps |"
echo "| Perte de paquets | ${PACKET_LOSS}% |"
EOF

chmod +x scripts/generate-report-from-prometheus.sh
./scripts/generate-report-from-prometheus.sh
```

### 2. Exporter un Dashboard en PDF
```bash
# Installer grafana-reporter
kubectl apply -f monitoring/grafana-reporter-deployment.yaml

# G√©n√©rer un PDF du dashboard
curl "http://localhost:8686/api/v5/report/nexslice-overview?apitoken=YOUR_API_TOKEN" > rapport_nexslice.pdf
```

### 3. Configurer des Alertes

Cr√©ez `monitoring/prometheus-alerts.yaml`:
```yaml
groups:
- name: nexslice_alerts
  interval: 30s
  rules:
  - alert: HighLatency
    expr: nexslice_rtt_avg_ms > 50
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Latence √©lev√©e d√©tect√©e"
      description: "La latence moyenne est de {{ $value }}ms (seuil: 50ms)"

  - alert: PacketLoss
    expr: nexslice_packet_loss_percent > 1
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Perte de paquets d√©tect√©e"
      description: "Perte de paquets: {{ $value }}% (seuil: 1%)"

  - alert: LowThroughput
    expr: nexslice_throughput_mbps < 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "D√©bit faible"
      description: "D√©bit: {{ $value }} Mbps (seuil: 10 Mbps)"
```

---

## üéØ Script 4: run-all-tests.sh (MASTER)

### Description
Orchestre l'ex√©cution de tous les tests avec export automatique vers Prometheus.

Le script g√©n√®re maintenant:
- M√©triques temps r√©el dans Prometheus
- Dashboards Grafana mis √† jour
- Rapport final avec lien vers Grafana

### R√©sultat Attendu
```
================================================
    NexSlice - Suite de Tests Compl√®te
    Monitoring: Prometheus + Grafana
================================================

Date: 2025-11-29 12:34:56
Log: results/test_run_20251129_123456.log

[√âtape 0/5] V√©rification du monitoring
================================================
‚úì Prometheus actif: http://localhost:30090
‚úì Pushgateway actif: http://localhost:30091
‚úì Grafana actif: http://localhost:30300

[...ex√©cution des tests...]

================================================
‚úì Suite de tests termin√©e avec succ√®s
================================================

üìÅ Tous les r√©sultats sont dans: results/

üìä Monitoring:
   - Prometheus: http://localhost:30090
   - Grafana: http://localhost:30300
   - Dashboard NexSlice: http://localhost:30300/d/nexslice

üìÑ Documents g√©n√©r√©s:
   - Rapport final: results/RAPPORT_FINAL_20251129_123456.md
   - Log complet: results/test_run_20251129_123456.log

üîç Prochaines √©tapes recommand√©es:
   1. Consulter le dashboard Grafana
   2. V√©rifier les alertes Prometheus
   3. Comparer les m√©triques avec les objectifs du projet
```

---

## üí° Conseils et Bonnes Pratiques

### 1. Monitoring Continu
```bash
# Lancer les tests toutes les 5 minutes
watch -n 300 './scripts/measure-performance.sh'

# Ou via cron
crontab -e
# Ajouter: */5 * * * * /path/to/scripts/measure-performance.sh
```

### 2. Cr√©er des Snapshots Grafana
```bash
# Sauvegarder l'√©tat du dashboard
curl -X POST http://localhost:30300/api/snapshots \
  -H "Content-Type: application/json" \
  -d @dashboard-snapshot.json
```

### 3. Exporter les M√©triques pour Analyse
```bash
# Exporter 24h de m√©triques
curl -G http://localhost:30090/api/v1/query_range \
  --data-urlencode 'query=nexslice_rtt_avg_ms{ue_ip="12.1.1.2"}' \
  --data-urlencode 'start=2025-11-28T00:00:00Z' \
  --data-urlencode 'end=2025-11-29T00:00:00Z' \
  --data-urlencode 'step=15s' > metrics_24h.json
```

---

## üéì Utilisation pour la Pr√©sentation

### Pr√©parer une D√©monstration Live
```bash
# 1. Ouvrir Grafana en plein √©cran
open http://localhost:30300/d/nexslice?refresh=5s&kiosk

# 2. Lancer les tests en arri√®re-plan
./scripts/run-all-tests.sh &

# 3. Montrer les m√©triques en temps r√©el
# Les graphiques se mettront √† jour automatiquement

# 4. Pointer vers des m√©triques cl√©s
# - Latence stable autour de 2-5ms
# - D√©bit constant √† 25-30 Mbps
# - Z√©ro perte de paquets
```

---

*Guide d'utilisation avec monitoring Prometheus & Grafana - Projet NexSlice - Groupe 4*